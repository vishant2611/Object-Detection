{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84c363f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "     --------------------------------------- 38.2/38.2 MB 13.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\visha\\anaconda3\\envs\\dab200\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n"
     ]
    }
   ],
   "source": [
    "#! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd5771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccdbae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\") \n",
    "#dnn deep neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94b7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a68b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coco_1.names\",\"r\") as file:\n",
    "    classes = [line.strip() for line in file.readlines()]\n",
    "layer_names = yolo.getLayerNames()\n",
    "# two main extraction layernames and getunconnectedoutlayer\n",
    "output_layers = [layer_names[i - 1] for i in yolo.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6ba0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n"
     ]
    }
   ],
   "source": [
    "print(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b1fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9a9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_Red = (0,0,255)\n",
    "color_Green = (0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd20da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"image_1.jpg\"\n",
    "img = cv2.imread(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfdc6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = img.shape\n",
    "# load image here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bfc88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(img,0.00392, (416,416), (0,0,0), True, crop= False)\n",
    "# blobfromimage remove all dependencies like light texture and it comes to the basic of basic \n",
    "#like some images are different in some places and same image is different in different place\n",
    "# so to remove that dependencies we use this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f383de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.setInput(blob)\n",
    "outputs_file = yolo.forward(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc627296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids  = []\n",
    "confidences = [] # to remove noise like other objects \n",
    "boxes = []\n",
    "for output in outputs_file:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "            \n",
    "            boxes.append([x,y,w,h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea687fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16, 16, 15, 16, 16, 16, 15, 15, 15, 15, 16, 15]\n",
      "[1 9]\n"
     ]
    }
   ],
   "source": [
    "indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "# NMS--> Non Maximum suppression When using object detection methods \n",
    "#it happens often, that the same object getâ€™s detected multiple times\n",
    "#in slightly different areas.then we use this to avoid multiple detection\n",
    "# boxes which detect they detect everything like noise also\n",
    "# to avaoid we use NMS\n",
    "# if we not use NMS there will be multiple boxes for single object\n",
    "print(class_ids)\n",
    "#print(list(set(class_ids)))\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f5b18886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file = open(\"coco_1.names\")\\nspecified_lines = [16,15]\\nfor pos, l_num in enumerate(file):\\n\\n    if pos in specified_lines:\\n        # print the required line number\\n        print(l_num)'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''file = open(\"coco_1.names\")\n",
    "specified_lines = [16,15]\n",
    "for pos, l_num in enumerate(file):\n",
    "\n",
    "    if pos in specified_lines:\n",
    "        # print the required line number\n",
    "        print(l_num)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd9f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 26, 735, 503]\n",
      "16\n",
      "[698, 59, 519, 517]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# to draw boxes\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x,y,w,h = boxes[i]\n",
    "        print(boxes[i])\n",
    "        print(class_ids[i])\n",
    "        label = str(classes[class_ids[i]])\n",
    "        #label = 'dog'\n",
    "        cv2.rectangle(img,(x,y),(x + w, y + h), color_Green, 3)\n",
    "        cv2.putText(img, label,(x , y + 10), cv2.FONT_HERSHEY_PLAIN,8, color_Red,8) # 8 is thickeness of font\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c81257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(boxes))\n",
    "print(len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f362d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\",img)\n",
    "cv2.imwrite(\"obj_det_\"+name,img) # name of new image\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb425d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
